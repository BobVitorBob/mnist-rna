{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.0 64-bit",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "06ab0ab1501f6d4c8c4d531367d1670a0759b6dba091323ca1e4b72d25dd6a88"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "\n",
    "    def __init__(self, n_neurons):\n",
    "        self.activation_function = sigmoid\n",
    "        self.d_activation_function = d_sigmoid\n",
    "        self.neurons = np.zeros(n_neurons)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Camada densa com \" + str(self.neurons.shape[0]) + \" neuronios e função de ativação \" + str(self.activation_function)\n",
    "\n",
    "\n",
    "class Sequential():\n",
    "\n",
    "    def salvar_pesos(self, diretorio='./'):\n",
    "        caminho = os.getcwd()\n",
    "        caminho = os.path.join(caminho, diretorio)\n",
    "        caminho = caminho + '_'\n",
    "        for camada in self.layers:\n",
    "            caminho = caminho + f'{camada.neurons.shape[1]}_'\n",
    "        caminho = caminho + f'.pkl'\n",
    "\n",
    "        with open(caminho, 'wb') as arq:\n",
    "            pickle.dump(self, arq, -1)\n",
    "        \n",
    "        print('Rede', caminho, 'salva!')\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        self.layers = []\n",
    "\n",
    "    def add_layer(self, camada):\n",
    "        self.layers.append(camada)\n",
    "        pass\n",
    "\n",
    "    def summary(self):\n",
    "        for layer in self.layers:\n",
    "            print(\"------------------------------------------------------------------------------------------------\")\n",
    "            print(layer)\n",
    "\n",
    "    def compile(self, error_function, d_error_function):\n",
    "        self.weights.append(np.random.rand( self.input_size, self.layers[0].neurons.shape[0] ) - 0.5)\n",
    "        self.bias.append(np.random.rand(self.layers[0].neurons.shape[0]))\n",
    "        self.error_function = erro_quadratico\n",
    "        self.d_error_function = d_erro_quadratico\n",
    "        i = 0\n",
    "        for layer in range(len(self.layers) - 1):\n",
    "            self.weights.append( np.random.rand( self.layers[i].neurons.shape[0], self.layers[i + 1].neurons.shape[0] ) - 0.5)\n",
    "            self.bias.append( np.random.rand(self.layers[i + 1].neurons.shape[0]) )\n",
    "            i+=1\n",
    "        \n",
    "        print(\"Pesos:\")\n",
    "        for weights in self.weights:\n",
    "            print(weights.shape)\n",
    "        print(\"Bias:\")\n",
    "        for bia in self.bias:\n",
    "            print(bia.shape)\n",
    "    \n",
    "    def feedforward(self, X):\n",
    "        self.layers[0].neurons = self.layers[0].activation_function(( X @ self.weights[0]) + self.bias[0])\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i].neurons = self.layers[i].activation_function((self.layers[i - 1].neurons @ self.weights[i]) + self.bias[i])  \n",
    "        return self.layers[-1].neurons\n",
    "\n",
    "    def backpropagation(self, X, Y, lr, show_info=False):\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "\n",
    "            if i == len(self.weights) - 1:\n",
    "                erro = self.d_error_function(self.layers[-1].neurons, Y)\n",
    "            else:\n",
    "                # print('pesos', self.weights[i + 1].shape)\n",
    "                # print('delta.T',delta.T.shape)\n",
    "                # print('(self.weights[i + 1] @ delta.T).T', erro.shape)\n",
    "                erro = (self.weights[i + 1] @ delta.T).T\n",
    "                # input()\n",
    "\n",
    "            delta = erro * self.layers[i].d_activation_function(self.layers[i].neurons)\n",
    "\n",
    "            if i == 0:\n",
    "                dw = delta.T @ X\n",
    "            else:\n",
    "                dw = delta.T @ self.layers[i - 1].neurons\n",
    "\n",
    "            self.weights[i] -= lr * dw.T\n",
    "            self.bias[i] -= lr * np.sum(delta, axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.feedforward(X)\n",
    "        return self.layers[-1].neurons\n",
    "\n",
    "    def fit(self, X, Y, X_val=[], Y_val=[], epochs=10, lr=0.01, stop_after=-1):\n",
    "        \"\"\"\n",
    "        Função de treino. Faz o treino sobre os conjuntos X e Y por epochs épocas. Após cada época o modelo calcula o erro em cima dos conjuntos de validação. Após finalizar o treino, o modelo retorna os pesos que tiveram o menor erro.\n",
    "        \"\"\"\n",
    "        menor_erro = 100_000\n",
    "        if stop_after < 0:\n",
    "            stop_after = epochs\n",
    "        if len(X_val) == 0:\n",
    "            X_val = X\n",
    "            Y_val = Y\n",
    "\n",
    "        start = time.time()\n",
    "        no_improvement = 0\n",
    "        lr = lr/X.shape[0]\n",
    "        for i in range(epochs):\n",
    "            self.feedforward(X)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            if i % 30 == 0:\n",
    "                self.backpropagation(X, Y, lr, True)\n",
    "            else:\n",
    "                self.backpropagation(X, Y, lr, False)\n",
    "\n",
    "            validation = self.predict(X_val)\n",
    "\n",
    "            erro = np.mean(self.error_function(validation, Y_val))\n",
    "\n",
    "            if erro < menor_erro:\n",
    "                no_improvement = 0\n",
    "                melhor_iteracao = i\n",
    "                menor_erro = erro\n",
    "                melhores_pesos = self.weights\n",
    "                melhores_bias = self.bias\n",
    "            else:\n",
    "                no_improvement+=1\n",
    "                if no_improvement == stop_after:\n",
    "                    break\n",
    "\n",
    "            if i % 30 == 0:\n",
    "                accuracy = 0\n",
    "                for val in range(validation.shape[0]):\n",
    "                    if validation[val].argmax() == Y_val[val].argmax():\n",
    "                        accuracy+=1\n",
    "                accuracy = accuracy/Y_val.shape[0]\n",
    "                complete = str((i/epochs)*100)\n",
    "                acc = str(accuracy * 100)\n",
    "                print(complete+\"% completo\")\n",
    "                print(\"Melhor Iteração:\", melhor_iteracao)\n",
    "                print(\"Menor Erro\", menor_erro)\n",
    "                print(\"Acurácia até agora:\", acc + \"%\")\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        complete = str((i/epochs)*100)\n",
    "        acc = str(accuracy * 100)\n",
    "        print(complete+\"% completo\")\n",
    "        print(\"Melhor Iteração:\", melhor_iteracao)\n",
    "        print(\"Menor Erro\", menor_erro)\n",
    "        print(\"Acurácia até agora:\", acc + \"%\")\n",
    "        clear_output(wait=True)\n",
    "        return melhores_pesos, melhores_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.e**-x)\n",
    "\n",
    "def d_sigmoid(sig_x):\n",
    "    return sig_x*(1-sig_x)\n",
    "\n",
    "def d_erro_quadratico(Y, D):\n",
    "    return 2*(Y - D)\n",
    "\n",
    "def erro_quadratico(Y, D):\n",
    "    return (D - Y)**2\n",
    "\n",
    "def erro_absoluto(Y, D):\n",
    "    return np.abs(D - Y)\n",
    "\n",
    "def d_erro_absoluto(Y, D):\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/MNIST.csv\", header=None).sample(frac=1)\n",
    "X_train = dataset[0:int(0.8 * len(dataset))]\n",
    "X_val = dataset[int(0.8 * len(dataset)):int(0.9 * len(dataset))]\n",
    "X_test = dataset[int(0.9 * len(dataset)):]\n",
    "Y_train = X_train.pop(784)\n",
    "Y_val = X_val.pop(784)\n",
    "Y_test = X_test.pop(784)\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "aaaa = {'zero': 0, 'um': 1, 'dois': 2, 'tres': 3, 'quatro': 4, 'cinco': 5, 'seis': 6, 'sete': 7, 'oito': 8, 'nove': 9}\n",
    "\n",
    "Y_train = np.array([aaaa[num] for num in Y_train])\n",
    "Y_val = np.array([aaaa[num] for num in Y_val])\n",
    "Y_test = np.array([aaaa[num] for num in Y_test])\n",
    "\n",
    "new_Y_train = []\n",
    "for ans in Y_train:\n",
    "    vec = [0,0,0,0,0,0,0,0,0,0]\n",
    "    vec[ans.get()] += 1\n",
    "    new_Y_train.append(vec)\n",
    "Y_train = np.array(new_Y_train)\n",
    "\n",
    "new_Y_val = []\n",
    "for ans in Y_val:\n",
    "    vec = [0,0,0,0,0,0,0,0,0,0]\n",
    "    vec[ans.get()] += 1\n",
    "    new_Y_val.append(vec)\n",
    "Y_val = np.array(new_Y_val)\n",
    "\n",
    "new_Y_test = []\n",
    "for ans in Y_test:\n",
    "    vec = [0,0,0,0,0,0,0,0,0,0]\n",
    "    vec[ans.get()] += 1\n",
    "    new_Y_test.append(vec)\n",
    "Y_test = np.array(new_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pesos:\n(784, 20)\n(20, 15)\n(15, 10)\nBias:\n(20,)\n(15,)\n(10,)\n"
    }
   ],
   "source": [
    "nn1 = Sequential(784)\n",
    "nn1.add_layer(Dense(300))\n",
    "nn1.add_layer(Dense(100))\n",
    "nn1.add_layer(Dense(10))\n",
    "nn1.compile(erro_quadratico, d_erro_quadratico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "68.97999999999999% completo\nMelhor Iteração: 5898\nMenor Erro 0.01234990343815729\nAcurácia até agora: 92.30000000000001%\n"
    }
   ],
   "source": [
    "nn1.weights, nn1.bias = nn1.fit(X_train, Y_train, X_val=X_val, Y_val=Y_val, epochs=10_000, lr=1, stop_after=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1000, 20)\n(1000, 15)\n(1000, 10)\nRede c:\\Users\\Pichau\\Desktop\\IA\\RNA_multicamada\\./_20_15_10_.pkl salva!\n"
    }
   ],
   "source": [
    "nn1.salvar_pesos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp1, vn1, fp1, fn1 = [], [], [], []\n",
    "\n",
    "for c in range(Y_test.shape[1]):\n",
    "    vp1.append(0) \n",
    "    vn1.append(0)\n",
    "    fp1.append(0)\n",
    "    fn1.append(0)\n",
    "\n",
    "output_nn1 = teste.predict(X_test)\n",
    "prediction = []\n",
    "for kick in output_nn1:\n",
    "    prediction.append([0,0,0,0,0,0,0,0,0,0])\n",
    "    prediction[-1][kick.argmax().get()]+=1 \n",
    "\n",
    "for predict_nn1, expected in zip(prediction, Y_test):\n",
    "    for n in range(expected.shape[0]):\n",
    "\n",
    "        if predict_nn1[n] == expected[n]:\n",
    "            if expected[n] == 0:\n",
    "                vn1[n]+=1\n",
    "            else:\n",
    "                vp1[n]+=1\n",
    "        else:\n",
    "            if expected[n] == 0:\n",
    "                fp1[n]+=1\n",
    "            else:\n",
    "                fn1[n]+=1\n",
    "\n",
    "vn1 = np.array(vn1)\n",
    "vp1 = np.array(vp1)\n",
    "fn1 = np.array(fn1)\n",
    "fp1 = np.array(fp1) \n",
    "\n",
    "precision1 = vp1/(vp1+fp1)\n",
    "recall1 = vp1/(vp1+fn1)\n",
    "accuracy1 = sum(vp1)/sum(vp1 + fn1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precision:  [0.98913043 1.         0.98969072 0.97058824 0.975      0.96590909\n 0.98901099 0.98305085 0.97169811 0.98305085]\nRecall:  [0.98913043 1.         1.         0.96116505 0.95121951 0.96590909\n 0.97826087 0.99145299 0.99038462 0.98305085]\nAccuracy:  0.982\n"
    }
   ],
   "source": [
    "print('Precision: ', precision1)\n",
    "print('Recall: ', recall1)\n",
    "print('Accuracy: ', accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"_300_100_10_.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(filename,'rb')\n",
    "teste = pickle.load(infile)\n",
    "infile.close()"
   ]
  }
 ]
}